# LLM-Based Recommendation

## 早期工作
- **Zero-shot Recommendation:**
  - LLMRank [[arxiv](https://arxiv.org/abs/2305.08845)] [[pdf](./LLM-Based-Rec-Papers/2305.08845v2.pdf)]
- **SFT Training 对齐推荐性能:**
  - TALLRec [[arxiv](https://arxiv.org/abs/2305.00447)] [[pdf](./LLM-Based-Rec-Papers/2305.00447v3.pdf)]
  - InstructRec [[arxiv](https://arxiv.org/abs/2305.07001)] [[pdf](./LLM-Based-Rec-Papers/2305.07001v1.pdf)]
- **DPO in Recommendation:**
  - S-DPO [[arxiv](https://arxiv.org/pdf/2406.09215)] [[pdf](./LLM-Based-Rec-Papers/2406.09215v3.pdf)]

## 模态注入 (Modality Injection)
- LLaRA [[arxiv](https://arxiv.org/abs/2312.02445)] [[pdf](./LLM-Based-Rec-Papers/sigir24-llara.pdf)]

## 推荐中的LLM解码 (Decoding in LLM for Recommendation)
- D3 [[arxiv](https://arxiv.org/abs/2406.14900)] [[pdf](./LLM-Based-Rec-Papers/2406.14900v3.pdf)]

## 推荐中的智能体 (Agent in Rec)
- Agent4Rec [[acm](https://dl.acm.org/doi/pdf/10.1145/3626772.3657844)] [[pdf](./LLM-Based-Rec-Papers/3626772.3657844.pdf)]

- InteRecAgent [[arxiv](https://arxiv.org/abs/2308.16505)] [[pdf](./LLM-Based-Rec-Papers/2308.16505v3.pdf)]

## LLM增强推荐 (LLM-Enhanced Recommendation)
- RLMRec [[arxiv](https://arxiv.org/abs/2310.15950)] [[pdf](./LLM-Based-Rec-Papers/2310.15950v5.pdf)]

- AlphaRec [[arxiv](https://arxiv.org/abs/2407.05441)] [[pdf](./LLM-Based-Rec-Papers/2407.05441v2.pdf)]

## 会话式推荐 (Conversational Recommendation)
- Large Language Models as Zero-Shot Conversational Recommenders [[acm](https://dl.acm.org/doi/pdf/10.1145/3583780.3614949)] [[pdf](./LLM-Based-Rec-Papers/3583780.3614949.pdf)]

## 基于代码本的推荐 (Codebook-Based Recommendation)
- TIGER [[nips](https://proceedings.neurips.cc/paper_files/paper/2023/file/20dcab0f14046a5c6b02b61da9f13229-Paper-Conference.pdf)] [[pdf](./papers/Recommender-Systems-with-Generative-Retrieval.pdf)]

- **如何设计代码本:**
  - How to Index Item IDs for Recommendation Foundation Models [[acm](https://dl.acm.org/doi/pdf/10.1145/3624918.3625339)] [[pdf](./LLM-Based-Rec-Papers/3624918.3625339.pdf)]
- **Item Tokenizer**
  - LETTER [[arxiv](https://arxiv.org/abs/2405.07314)] [[pdf](./LLM-Based-Rec-Papers/2405.07314v2.pdf)]


## 与LLM结合的推荐 (Combination with LLM)
- LC-Rec [[arxiv](https://arxiv.org/abs/2311.09049)] [[pdf](./papers/Adapting-LLMs-by-Integrating-Collaborative-Semantics-for-Recommendation.pdf)]

---

## Must Know, But Do Not Need to Read
- **Scaling in Recommendation:**
  - HSTU [[arxiv](https://arxiv.org/abs/2402.17152)] [[pdf](./LLM-Based-Rec-Papers/2402.17152v3.pdf)]

- **Basic Models:**
  - LightGCN [[arxiv](https://arxiv.org/abs/2002.02126)] [[pdf](./LLM-Based-Rec-Papers/2002.02126v4.pdf)]
  - SASRec [[arxiv](https://arxiv.org/pdf/1808.09781)] [[pdf](./LLM-Based-Rec-Papers/1808.09781v1.pdf)]
- **Amazon 2023 数据集:**
  - Amazon 2023 Dataset [[arxiv](https://arxiv.org/abs/2403.03952)] [[pdf](./LLM-Based-Rec-Papers/2403.03952v1.pdf)]
